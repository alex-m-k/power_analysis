---
title: "Preliminary power analysis"
# author: Alex K
# date: 3/29/2020
output: 
  prettydoc::html_pretty:
    theme: leonids
    highlight: github
        # keep_md: TRUE
bibliography: power.bib
    
---

```{r setup, include=FALSE}

# Global display options
knitr::opts_chunk$set(message=FALSE, 
                      idy.opts=list(width.cutoff=60),
                      fig.align="center") 

knitr::knit_hooks$set(inline = function(x) { 
  if(!is.numeric(x)){ x }
  else{prettyNum(round(x,2), big.mark=",") } })

# Packages
library(knitr)
library(kableExtra)
library(tidyverse)
library(RColorBrewer)

# Graphic print options 
plot_theme <- theme(panel.border = element_blank(), 
                    panel.grid.major = element_blank(),
                    panel.grid.minor = element_blank(), 
                    axis.line = element_line(colour = "black"),
                    legend.text=element_text(size=8), 
                    legend.title=element_blank(),
                    legend.key = element_rect(colour = NA)) +
  theme_bw()

```

# Summary

/This could change/ So far, it looks to me like we should be good to detect an effect, based on two steps.

# Estimating our study's likely power and minimal detectable effect size 

Here, I walk through several methods for conducting power analyses. Power analysis grows more complex as our design grows more complex. Nearly any of the models we intend to run are complex enough that no off-the-shelf method for conducting power analyses will suffice. As a preliminary step, I thus perform a power analysis of perhaps the simplest sort we might do and still stay close to our design. I look at our likely power to detect an effect for a change in perceived stress in our survey. In this case, we are dealing with repeated measures (pre- and post-) on individual subjects within clusters. This is already more complicated than textbook examples; below I suggest ways we could try to make the power analysis more to true to reality. 

The good news is that because we will have pre and post observations, clustering should be less of a concern than if we only had a single cross-section.

The bad news is that the standard ICC no longer works. We don't just have to account for the time invariant effects of clusters but also the time invariant effects due to individual subjects' idiosyncracies. We therefore need a more complex ICC, which requires more parameters and/or data to be estimated.

I see three ways forward:

1. Take the parameters that we can get from existing studies [e.g., @Kossek_2019]
2. Use underlying data from an existing study
3. Simulate our own data

In what follows, I attempt 1 and 3. The middle option, 2, might actually be the easiest if we had some real data to work with. (Note: we'd just be using this data to get a few more summary statistics than the usual ones reported in a journal article.)

## Using parameters from existing studies

Here I conduct a power analysis using formulas provided by @McConnell_2015; [see @Teerenstra_2012; and @moyer2019correct as well]. 

The minimum detectable effect (MDE) for a difference-in-differences with two periods is:

$$\delta = \sqrt{\frac{2\sigma_22(1 - r)(t_{\alpha/2} t_{\beta})^2 (1 + (m - 1)\rho)}{ mk}}$$

And for a model that includes the baseline outcome as a covariate:

$$\delta = \sqrt{\frac{2\sigma_2(1 - r)(t_{\alpha/2} t_{\beta})^2 (1 + (m - 1)\rho)}{ mk}}$$

Note that in the second equation, the coefficient before $(1-r)$ is dropped, which has the desirable affect of reducing the MDE.

The ICC is captured by $\rho$, which in this case is equal to:

$$\rho = \frac{\sigma_{c}^2 + \sigma_{ct}^2}{\sigma_{c}^2 + \sigma_{ct}^2 + \sigma_{p}^2 + \sigma_{pt}^2}$$

where $\sigma_{c}^2$ and $\sigma_{ct}^2$ are equal to the time-invariant between cluster variance and time-varying within cluster variance and $\sigma_{p}^2$ and $\sigma_{pt}^2$ are equal to the time-invariant between persion variance and time-varying within person variance. These can be decomposed into person and cluster autocorrelation:

$$ 
\begin{array}
{ccc}
\rho_c = \frac{\sigma_{c}^2}{\sigma_{c}^2 + \sigma_{ct}^2} & \text{and} & \rho_p = \frac{\sigma_{p}^2}{\sigma_{p}^2 + \sigma_{pt}^2}
\end{array}
$$

The parameter $r$, the fraction of the total variance composed of by the time invariant components, is equal to:

$$r = \frac{m\rho}{1 + (m - 1)\rho}\rho_c + \frac{1-\rho}{1 + (m - 1)\rho}\rho_p$$
By conditioning on the baseline value of the outcome variable, we are netting out the time invariant component of the variance (which is large when $r$ is close to 1).

To use these equations to estimate an MDE, we need to set several parameters. These are:

Number of clusters, $k$:
```{r}
k <- 24
```

Number of observations in each cluster, $m$:
```{r}
m <- 122
```

Degrees of freedom, $df$:
```{r}
df <- 2 * (k - 1)
```

The significance level, $\alpha$
```{r}
alpha <- 0.05
t_alpha <- abs(qt((alpha / 2), df))
```

Power, $\beta$
```{r}
beta <- 0.80
t_beta <- abs(qt((beta / 2), df))
```

Variances. This is where things get tricky. We don't have an estimate for each variance. What I will attempt to do is set one variance based on @Kossek_2019 and then play around with the others. Note that I am not entirely sure I am using the Kossek values correctly. 

\setlength{\leftskip}{2cm}

Overall variance, $\sigma^2$, can, I believe, be derived using @Kossek_2019, Table 2. That is, we sum the variance of the baseline and 6-month outcome because 
$$var(x + y) = var(x) + var(y) + cov(x, y)$$
and because--and this where I am not certain--we can derive the covariance from the correlation provided in Table 2:
$$corr = \frac{cov(x, y)}{\sigma_x \sigma_y}$$
I treat $x$ as baseline perceived stress ($\mu$ = 9.51, $\sigma$ = 3.08) and $y$ as 6-months perceived stress ($\mu$ = 9.25, $\sigma$ = 2.93), and $corr$ is equal to 0.56. Hence, 

$$cov(x, y) = .56 \cdot 3.08 \cdot 2.93 = 5.053664$$
and

```{r}
sigma2 <- (3.08)^2 + (2.93)^2 + 5.053664
```

\setlength{\leftskip}{0pt}

The ICC, \rho, which for now we will assume a set value.
```{r}
rho <- 0.02
```

The fraction of the total variance composed of by the time invariant components, $r$, which we will allow to vary because we don't have good values which to estimate it:
```{r}
r <- seq(0, 1, .01)
```

Together, these allow us to estimate the MDE, $\delta$:
```{r}
# For diff-in-diffs
delta_dd <- sqrt((2* sigma2 * 2 *(1 - r) * (t_alpha + t_beta)^2 * (1 + (m - 1) * rho)) / (m*k))

# For pretreatment as covariate
delta_cov <- sqrt((2* sigma2 * (1 - r) * (t_alpha + t_beta)^2 * (1 + (m - 1) * rho)) / (m*k))
```

We can see how $\delta$ varies over ranges of $r$.
```{r power_plot_1, echo = FALSE}

dat <- data.frame(r, delta_dd, delta_cov)

ggplot(dat,
       aes(x = r)) +
  geom_line(aes(y=delta_dd, color="Diff-in-diffs")) +
  geom_line(aes(y=delta_cov, color= "Baseline as covariate")) +
  plot_theme +
  labs(title = "Power over range of r values",
       x = "r, time invariant variance fraction",
       y = "MDE") +
  theme(legend.title=element_blank())
```
And we can see how $\delta$ varies over ranges of $r$ and $\rho$.
```{r power_plot_2, echo = FALSE}
# Note: the below should be vectorized
# a = 0.01
rho_a <- 0.01
# b = 0.02
rho_b <- 0.02
# c = 0.03
rho_c <- 0.03
# d = 0.04
rho_d <- 0.04
# e = 0.05
rho_e <- 0.05
# f = 0.04
rho_f <- 0.1

# For diff-in-diffs
delta_dd_a <- sqrt((2* sigma2 * 2 *(1 - r) * (t_alpha + t_beta)^2 * (1 + (m - 1) * rho_a)) / (m*k))
delta_dd_b <- sqrt((2* sigma2 * 2 *(1 - r) * (t_alpha + t_beta)^2 * (1 + (m - 1) * rho_b)) / (m*k))
delta_dd_c <- sqrt((2* sigma2 * 2 *(1 - r) * (t_alpha + t_beta)^2 * (1 + (m - 1) * rho_c)) / (m*k))
delta_dd_d <- sqrt((2* sigma2 * 2 *(1 - r) * (t_alpha + t_beta)^2 * (1 + (m - 1) * rho_d)) / (m*k))
delta_dd_e <- sqrt((2* sigma2 * 2 *(1 - r) * (t_alpha + t_beta)^2 * (1 + (m - 1) * rho_e)) / (m*k))
delta_dd_f <- sqrt((2* sigma2 * 2 *(1 - r) * (t_alpha + t_beta)^2 * (1 + (m - 1) * rho_f)) / (m*k))

delta_dd_af <- data.frame(delta_dd_a,
                     delta_dd_b,
                     delta_dd_c,
                     delta_dd_d,
                     delta_dd_e,
                     delta_dd_f)
delta_dd_af <- gather(delta_dd_af, rho_dd, mde_dd, delta_dd_a:delta_dd_f)

# For pretreatment as covariate
delta_cov_a <- sqrt((2* sigma2 *(1 - r) * (t_alpha + t_beta)^2 * (1 + (m - 1) * rho_a)) / (m*k))
delta_cov_b <- sqrt((2* sigma2 *(1 - r) * (t_alpha + t_beta)^2 * (1 + (m - 1) * rho_b)) / (m*k))
delta_cov_c <- sqrt((2* sigma2 *(1 - r) * (t_alpha + t_beta)^2 * (1 + (m - 1) * rho_c)) / (m*k))
delta_cov_d <- sqrt((2* sigma2 *(1 - r) * (t_alpha + t_beta)^2 * (1 + (m - 1) * rho_d)) / (m*k))
delta_cov_e <- sqrt((2* sigma2 *(1 - r) * (t_alpha + t_beta)^2 * (1 + (m - 1) * rho_e)) / (m*k))
delta_cov_f <- sqrt((2* sigma2 *(1 - r) * (t_alpha + t_beta)^2 * (1 + (m - 1) * rho_f)) / (m*k))
  
delta_cov_af <- data.frame(delta_cov_a,
                     delta_cov_b,
                     delta_cov_c,
                     delta_cov_d,
                     delta_cov_e,
                     delta_cov_f)
delta_cov_af <- gather(delta_cov_af, rho_cov, mde_cov, delta_cov_a:delta_cov_f)

dat_af <- cbind(r, 
                delta_dd_af, 
                delta_cov_af)

dat_af$rho_dd <- as.factor(dat_af$rho_dd)
levels(dat_af$rho_dd) <- c("rho = 0.01",
                          "rho = 0.02",
                          "rho = 0.03",
                          "rho = 0.04",
                          "rho = 0.05",
                          "rho = 0.1")

ggplot(dat_af,
       aes(x = r)) +
  geom_line(aes(y=mde_dd, color="Diff-in-diffs")) +
  geom_line(aes(y=mde_cov, color= "Baseline as covariate")) +
  plot_theme +
    facet_wrap(~rho_dd) + 
  labs(title = "Power over range of r and rho values",
       x = "r, time invariant variance fraction",
       y = "MDE") +
  theme(legend.title=element_blank())



```

What does this imply for our MDE? If we assume $rho$ is equal to 0.02 and $r$ is equal to 0.50 (which I am selecting abritrarily), we would have and MDE equal to 0.527. The standard deviation of this outcome in @Kossek_2019 is 4.809 ($\sqrt{\sigma^2}$). If we divide the MDE by $\sigma^2$, we get 0.11, which Cohen's guideline is small standardized effect size.[^1]

Ideas for improving this measure:

* Look at existing studies to come up with guesses for $\rho_p$ and $\rho_c$, which would allow us to finetune the value of $r$.

[^1]: I could use help verifying that the MDE I generating ($\delta$) is not already standardized. In other words, is 0.527 in units of perceived stress or in standard deviations?


## Simulating our own data

## References
